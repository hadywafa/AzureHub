# â¬‡ï¸ Download the ready-to-run project

[Download the project ZIP](sandbox:/mnt/data/owasp-zap-pipeline-demo.zip)

It contains:

```ini
/app                 # Node/Express demo app (target for ZAP)
 /infra              # (placeholder if you want to add bicep later)
 /tools
   zap_eval.py       # converts ZAP JSON -> JUnit + SARIF, enforces thresholds
   run_zap.sh        # local helper to run baseline scan in Docker
azure-pipelines.yml  # multi-stage pipeline (Build â†’ Dev â†’ Prod)
README.md            # step-by-step runbook
```

---

## ðŸ§­ Quick start

1. **Create** an Azure RM **service connection** in Azure DevOps named `sc-azure`.
2. **Open** `azure-pipelines.yml` and change the variables (theyâ€™re all at the top):

   ```yaml
   variables:
   azureServiceConnection: "sc-azure"
   location: "eastus"
   devResourceGroup: "rg-zap-demo-dev"
   prodResourceGroup: "rg-zap-demo-prod"
   planName: "asp-zap-demo"
   devWebAppName: "zap-demo-web-dev" # must be globally unique
   prodWebAppName: "zap-demo-web-prod" # must be globally unique
   storageAccount: "zapdemostorage1234" # must be globally unique
   storageContainer: "zap-results"
   ```

3. **Make sure** the service connection identity has **Storage Blob Data Contributor** on the storage account (for upload/download in the Dev stage).
4. Create a pipeline from `azure-pipelines.yml` and run it.

---

## ðŸ§± What the pipeline does

### Stage: **Build**

- Builds the Node app and publishes `app.zip` artifact.

### Stage: **Development**

1. **Deploy** (AzureCLI\@2)

   - Ensures RG, App Service Plan, and Dev Web App exist.
   - Deploys the artifact.

2. **Create Storage & Container**

   - Ensures Storage Account + Blob Container for results.

3. **Run ZAP scan**

   - Runs **OWASP ZAP baseline** via Docker against the Dev URL.
   - Saves `zap_report.html/json/xml`.

4. **Download & Transform**

   - Uploads to Blob Storage (for traceability), then downloads to the agent.
   - `tools/zap_eval.py` converts JSON â†’ **JUnit** (for Tests tab) + **SARIF** (for scanners)
   - Enforces thresholds: **fail on any High OR any Medium** by default.

5. **Publish**

   - Publishes test results + artifacts (`zap-raw`, `zap-processed`).

6. **Delete Container (optional)**

   - Cleans the temporary blob container.

### Stage: **Production**

- Deploys to **Prod** App Service **only if** Development succeeded (i.e., ZAP gate passed).

---

## ðŸ”Ž Key files (already in the ZIP)

### `azure-pipelines.yml` (excerpt: ZAP job)

```yaml
- job: ZapScan
  displayName: "Run ZAP Scan against Dev"
  steps:
    - task: Bash@3
      displayName: "Run OWASP ZAP Baseline (Docker)"
      inputs:
        targetType: inline
        script: |
          set -e
          mkdir -p "$(zapOutDir)"
          docker pull owasp/zap2docker-stable
          docker run --rm -t -v "$(zapOutDir):/zap/wrk" owasp/zap2docker-stable \
            zap-baseline.py -t "$(devUrl)" -r zap_report.html -J zap_report.json -x zap_report.xml -m 5 -d
          ls -la "$(zapOutDir)"

    - task: AzureCLI@2
      displayName: "Upload ZAP results to Storage"
      inputs:
        azureSubscription: $(azureServiceConnection)
        scriptType: bash
        scriptLocation: inlineScript
        inlineScript: |
          az storage blob upload-batch \
            --account-name "$(storageAccount)" \
            --auth-mode login \
            -d "$(storageContainer)" \
            -s "$(zapOutDir)"

    - task: AzureCLI@2
      displayName: "Download ZAP results back to pipeline (for transform/publish)"
      inputs:
        azureSubscription: $(azureServiceConnection)
        scriptType: bash
        scriptLocation: inlineScript
        inlineScript: |
          mkdir -p $(Pipeline.Workspace)/zap-download
          az storage blob download-batch \
            --account-name "$(storageAccount)" \
            --auth-mode login \
            -d "$(Pipeline.Workspace)/zap-download" \
            -s "$(storageContainer)"

    - task: UsePythonVersion@0
      inputs:
        versionSpec: "3.x"

    - script: |
        python3 tools/zap_eval.py \
          --json "$(Pipeline.Workspace)/zap-download/zap_report.json" \
          --junit "$(Build.ArtifactStagingDirectory)/zap-junit.xml" \
          --sarif "$(Build.ArtifactStagingDirectory)/zap.sarif" \
          --fail-high --max-medium 0
      displayName: "Transform ZAP JSON -> JUnit + SARIF (fail on High/Medium)"

    - task: PublishTestResults@2
      inputs:
        testResultsFormat: "JUnit"
        testResultsFiles: "$(Build.ArtifactStagingDirectory)/zap-junit.xml"
        testRunTitle: "OWASP ZAP"

    - task: PublishBuildArtifacts@1
      inputs:
        pathToPublish: "$(Pipeline.Workspace)/zap-download"
        artifactName: "zap-raw"

    - task: PublishBuildArtifacts@1
      inputs:
        pathToPublish: "$(Build.ArtifactStagingDirectory)"
        artifactName: "zap-processed"
```

### `tools/zap_eval.py` (what it enforces)

- Reads `zap_report.json`
- Counts **High/Medium/Low**
- Generates **JUnit** & **SARIF**
- **Exits non-zero** if:

  - any **High** (`--fail-high`)
  - any **Medium** (`--max-medium 0`)
  - (you can adjust thresholds)

---

## ðŸ§ª Local testing (optional)

```bash
# run the web app locally
cd app && npm ci && npm start   # opens on http://localhost:8080

# run ZAP baseline locally
cd ../tools
./run_zap.sh http://localhost:8080 ../local-zap-out
python3 zap_eval.py --json ../local-zap-out/zap_report.json --junit junit.xml --sarif zap.sarif --fail-high --max-medium 0
```

---

## ðŸ“Œ Notes & best practices

- This demo uses **baseline scan** (safe). For deeper testing in non-prod, switch to `zap-full-scan.py`.
- When using `--auth-mode login` on storage commands, grant your service connection identity **Storage Blob Data Contributor** on that storage account.
- Keep **prod** behind approvals (ADO environments) and only deploy if ZAP passes.
- Pair ZAP with **SonarQube/SonarCloud** to cover both **runtime** and **code** issues.
