# üèóÔ∏è Azure Data Factory (ADF) ‚Äî The Cloud Data Orchestrator ‚öôÔ∏è

## üåç What Is Azure Data Factory?

> **Azure Data Factory (ADF)** is a **fully managed, serverless data integration service** that lets you **ingest, transform, and orchestrate data flows** across **on-premises, multi-cloud, and SaaS** systems.

---

> üí¨ In simple terms:  
> ADF is like an **air traffic controller ‚úàÔ∏è** for all your data pipelines ‚Äî  
> telling each dataset _when_, _where_, and _how_ to move and transform.

---

<div style="text-align:center; background-color:#ffff; border-radius: 10px; border: solid">
<img src="image/1760010822631.png" alt="On Premises File Server" style="width: 60%;">
</div>

---

## üß† Why Use Azure Data Factory?

| Problem                                              | ADF Solution                        |
| ---------------------------------------------------- | ----------------------------------- |
| You have data in 10 different systems                | ADF connects them all               |
| You need to run daily ETL jobs                       | ADF schedules and orchestrates them |
| You need to move data from on-prem to cloud securely | ADF uses Integration Runtime (IR)   |
| You need visual data transformations                 | ADF Data Flows                      |
| You want to trigger Databricks / SQL / API workflows | ADF activities                      |

---

## ‚öôÔ∏è ADF = Integration + Transformation + Orchestration

ADF combines three main layers:

| Layer              | Description                             | Example                       |
| ------------------ | --------------------------------------- | ----------------------------- |
| **Integration**    | Connect to 100+ data sources            | SQL, Oracle, Salesforce, Blob |
| **Transformation** | Transform with Data Flows or Databricks | Clean, aggregate, enrich      |
| **Orchestration**  | Schedule, monitor, retry                | Run daily 2AM jobs            |

---

## üß© Azure Data Factory Components

Here‚Äôs how the pieces fit together:

| Component                    | Description                                | Analogy           |
| ---------------------------- | ------------------------------------------ | ----------------- |
| **Pipeline**                 | Logical container of activities            | Recipe            |
| **Activity**                 | Single task (copy, run notebook, call API) | Step in recipe    |
| **Linked Service**           | Connection info to a data source           | Kitchen appliance |
| **Dataset**                  | Structure or schema of data                | Ingredients       |
| **Trigger**                  | Defines when pipeline runs                 | Alarm clock       |
| **Integration Runtime (IR)** | The compute engine to execute              | Chef              |

---

<div style="text-align:center; background-color:#292E3F; border-radius: 10px; border: solid">
<img src="image/1760009237896.png" alt="On Premises File Server" style="width: 80%;">
</div>

---

## üß± Visual Overview

<div align="center" style="background-color: #1b3f47ff; border-radius: 10px;">

```mermaid
---
config:
  theme: dark
---
flowchart TD
    A[Data Sources<br>SQL, Blob, Oracle, SAP, APIs] --> B[ADF Pipeline]
    B -->|Copy Activity| C[Data Lake / SQL / Cosmos DB]
    B -->|Transform| D[Data Flow / Databricks / Synapse]
    B -->|Orchestrate| E[Power BI / ML / Notifications]
```

</div>

üß† So ADF acts as your **data workflow conductor**, integrating all services.

---

## üß© Supported Connectors (Over 100+)

ADF can connect to nearly any data source:

| Category         | Examples                                    |
| ---------------- | ------------------------------------------- |
| **Azure**        | Blob, Data Lake, SQL DB, Synapse, Cosmos DB |
| **On-premises**  | SQL Server, Oracle, Teradata, MySQL         |
| **SaaS Apps**    | Salesforce, Dynamics, SAP, ServiceNow       |
| **Other Clouds** | AWS S3, Redshift, Google BigQuery           |
| **NoSQL & File** | MongoDB, Cassandra, FTP, API endpoints      |

‚úÖ **No need to write code** ‚Äî just configure via UI or JSON.

---

## üß™ Hands-On Walkthrough

Let‚Äôs create your **first data pipeline** step by step üëá

---

### ü™ú Step 1Ô∏è‚É£ ‚Äî Create Azure Data Factory

1. Go to **Azure Portal ‚Üí Create a Resource ‚Üí Data Factory**
2. Fill in:

   - **Name:** `my-adf-pipeline`
   - **Region:** same as your data
   - **Version:** V2 (current)
   - **Git Integration (optional):** enable if using GitHub/Azure Repos

3. Click **Review + Create ‚Üí Create**

‚úÖ Once deployed ‚Üí open **ADF Studio** from the portal.

---

### ü™ú Step 2Ô∏è‚É£ ‚Äî Create a Pipeline

1. In ADF Studio, go to **Author ‚Üí Pipelines ‚Üí + New pipeline**
2. Name it: `CopySalesData`
3. From the **Activities pane**, drag **Copy Data** into the canvas.

---

### ü™ú Step 3Ô∏è‚É£ ‚Äî Define Source & Destination

1. In the **Source tab**, click ‚Äú+ New‚Äù to create a **Linked Service**
   ‚Üí choose **Azure Blob Storage** (your raw data).
2. In the **Sink tab**, add another linked service:
   ‚Üí choose **Azure SQL Database** or **Synapse SQL Pool**.
3. Set **input dataset** (CSV) and **output dataset** (SQL Table).

---

### ü™ú Step 4Ô∏è‚É£ ‚Äî Add Mapping (Optional)

- Map CSV columns ‚Üí SQL columns manually if names differ.

Example:

| CSV Column  | SQL Column  |
| ----------- | ----------- |
| ProductName | ProductName |
| Quantity    | Qty         |
| Amount      | Total       |

---

### ü™ú Step 5Ô∏è‚É£ ‚Äî Publish and Run

- Click **Publish All**
- Click **Debug** (for test run) or **Add Trigger ‚Üí Now** to execute.
- Check **Monitor** tab for run status.

‚úÖ You just built your first pipeline ‚Äî no code, all visual.

---

## ‚ö° Data Flow (Visual Transformations)

When you need **data cleaning or transformation** (not just copying), use **Mapping Data Flows**.

It‚Äôs a **visual ETL designer** (no Spark coding needed).
Behind the scenes ‚Äî it runs on **Azure Databricks Spark clusters**.

### Example transformations:

- Filter rows
- Join datasets
- Aggregate values
- Derive new columns
- Write to destination

<div align="center" style="background-color: #1b3f47ff; border-radius: 10px;">

```mermaid
---
config:
  layout: elk
  elk:
    mergeEdges: false
    nodePlacementStrategy: LINEAR_SEGMENTS
---
flowchart LR
    A[CSV Input] --> B[Filter: Amount > 1000]
    B --> C[Join: Customers]
    C --> D[Aggregate by Region]
    D --> E[Write to Data Lake / SQL]
```

</div>

---

## üß© Control Flow Activities

ADF also lets you manage logic ‚Äî like **if-else, loops, variables** ‚Äî similar to programming.

| Activity             | Description                      |
| -------------------- | -------------------------------- |
| **If Condition**     | Branch logic based on expression |
| **ForEach**          | Loop over list of items          |
| **Wait**             | Pause pipeline for a duration    |
| **Execute Pipeline** | Call another pipeline            |
| **Set Variable**     | Manage runtime variables         |

Example:

> For each region ‚Üí copy the data ‚Üí clean it ‚Üí load to SQL.

---

## üïí Triggers

| Type                | Description             | Example                     |
| ------------------- | ----------------------- | --------------------------- |
| **Manual**          | Run manually            | Ad-hoc run                  |
| **Schedule**        | Time-based              | Every night at 2 AM         |
| **Tumbling Window** | Periodic, with catch-up | Every 15 mins               |
| **Event-based**     | File arrival            | When new file lands in Blob |

---

## üß† Integration Runtime (IR)

<div align="center" style="background-color: #1b3f47ff; border-radius: 10px;">

| Type                   | Description                | Use Case                 |
| ---------------------- | -------------------------- | ------------------------ |
| **Azure IR (default)** | Fully managed by Azure     | Cloud-to-cloud copy      |
| **Self-hosted IR**     | Installed on your VM       | On-prem to cloud         |
| **Azure-SSIS IR**      | Run SSIS packages in Azure | Lift & shift legacy SSIS |

</div>

<div style="text-align:center; background-color:#292E3F; border-radius: 10px; border: solid">
<img src="image/1760009427598.png" alt="On Premises File Server" style="width: 60%;">
</div>

---

üí° ADF **automatically chooses** the right IR for you unless you customize it.

---

## üîê Security in ADF

| Feature                   | Description                        |
| ------------------------- | ---------------------------------- |
| **Managed Identity**      | Connect to Azure services securely |
| **Private Endpoints**     | Keep traffic inside VNet           |
| **Key Vault Integration** | Store secrets safely               |
| **RBAC + Azure AD**       | Control who can run pipelines      |

---

## üí∏ Pricing Model (Simple!)

| Category                | Pricing Unit           | Example                     |
| ----------------------- | ---------------------- | --------------------------- |
| **Pipeline Runs**       | Per activity execution | \$0.25 per 50 runs          |
| **Data Flow Compute**   | Per vCore-hour         | Pay for transformation time |
| **Integration Runtime** | Per hour               | Only for self-hosted IR     |
| **Triggers**            | Free                   | Scheduling is free          |

üß† **Tip:**
Pause or delete unnecessary triggers ‚Äî ADF doesn‚Äôt charge when idle!

---

## üß© ADF vs Synapse Pipelines

| Feature         | **Azure Data Factory**          | **Synapse Pipelines**        |
| --------------- | ------------------------------- | ---------------------------- |
| **Scope**       | Enterprise-wide ETL             | Analytics-focused ETL        |
| **Integration** | Works across 100+ systems       | Tight with Synapse workspace |
| **UI**          | ADF Studio                      | Synapse Studio               |
| **Engine**      | Same (ADF engine)               | Same engine                  |
| **Best For**    | Hybrid, multi-cloud integration | Analytics pipelines          |
| **Pricing**     | Pay per activity                | Pay per activity             |

üß≠ **Rule of Thumb:**

- Use **ADF** for _enterprise-scale data movement_ (ERP, CRM, on-prem).
- Use **Synapse Pipelines** for _analytics-specific data workflows_.

---

## üß© Real-World Example

| Step | Task                                           | Tool                  |
| ---- | ---------------------------------------------- | --------------------- |
| 1Ô∏è‚É£   | Copy daily sales from on-prem SQL ‚Üí Azure Blob | Copy Activity         |
| 2Ô∏è‚É£   | Clean data (remove nulls, rename cols)         | Data Flow             |
| 3Ô∏è‚É£   | Enrich with region data                        | Join Activity         |
| 4Ô∏è‚É£   | Load to Synapse SQL                            | Sink Activity         |
| 5Ô∏è‚É£   | Refresh Power BI dataset                       | Web Activity          |
| 6Ô∏è‚É£   | Email success/failure report                   | Logic App integration |

‚úÖ This entire pipeline is automated and monitored in ADF Studio.

---

## üßæ Summary

| Concept             | Description                                        |
| ------------------- | -------------------------------------------------- |
| **ADF Purpose**     | Data integration & orchestration across systems    |
| **Core Components** | Pipelines, Datasets, Linked Services, IR, Triggers |
| **Transformation**  | Visual Data Flows / Notebooks                      |
| **Security**        | Managed Identity + Key Vault                       |
| **Cost**            | Pay per pipeline execution                         |
| **Integration**     | Works with Synapse, Databricks, Power BI           |
| **Type**            | Serverless, PaaS                                   |

---

‚úÖ **In one line:**

> **Azure Data Factory** is your **data transport and transformation engine** ‚Äî
> it automates, moves, and cleans data from anywhere to anywhere ‚Äî no servers, no maintenance, all orchestrated in the cloud.

---

<div style="text-align:center; background-color:#ffff; border-radius: 10px; border: solid">
<img src="image/1760029012024.png" alt="On Premises File Server" style="width: 60%;">
</div>

<div style="text-align:center; background-color:#ffff; border-radius: 10px; border: solid">
<img src="image/1760010657319.png" alt="On Premises File Server" style="width: 60%;">
</div>

<div style="text-align:center; background-color:#ffff; border-radius: 10px; border: solid">
<img src="image/1760010699103.png" alt="On Premises File Server" style="width: 60%;">
</div>

<div style="text-align:center; background-color:#ffff; border-radius: 10px; border: solid">
<img src="image/1760010693152.png" alt="On Premises File Server" style="width: 60%;">
</div>
