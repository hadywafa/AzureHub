# 1ï¸âƒ£ First: What is Azure CNI Overlay (in simple words)

**Azure CNI Overlay =**

- Pods get **private IPs from an overlay network (not from your VNet subnet)**
- Nodes still live in your **Azure VNet**
- Azure handles **NAT + routing** between:

  - Pods â†” Nodes â†” VNet â†” Internet

ðŸ‘‰ Think of it as:

> â€œPods live in their own invisible network on top of Azure networkingâ€

---

## 2ï¸âƒ£ Why Azure created Overlay mode (the problem it solves)

### Traditional Azure CNI (non-overlay) problem

- Pods get **real VNet IPs**
- Every pod **consumes a subnet IP**
- Large clusters = **IP exhaustion nightmare**

### Overlay solution

- Pods use **internal overlay CIDR** (e.g. `10.244.0.0/16`)
- Subnet IPs are used **only by nodes**
- Azure handles translation behind the scenes

âœ… Result: **Massive IP savings**

---

## 3ï¸âƒ£ High-level architecture (mental picture)

![Image](https://learn.microsoft.com/en-us/azure/aks/media/azure-cni-overlay/azure-cni-overlay.png?utm_source=chatgpt.com)

![Image](https://i.ytimg.com/vi/qLRB9_DlABg/maxresdefault.jpg?utm_source=chatgpt.com)

![Image](https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/scenarios/app-platform/aks/media/network-private-cluster.png?utm_source=chatgpt.com)

### Components involved

| Component     | Role                   |
| ------------- | ---------------------- |
| **AKS Node**  | Has a real VNet IP     |
| **Pod**       | Gets an overlay IP     |
| **Azure CNI** | Sets up networking     |
| **SNAT**      | Translates pod traffic |
| **VNet**      | Only sees node IPs     |

---

## 4ï¸âƒ£ IP addressing in Overlay mode

### Example setup

```text
VNet Subnet:     10.0.0.0/16
Node IPs:        10.0.1.4, 10.0.1.5
Pod CIDR:        10.244.0.0/16 (overlay)
```

### On a node

```text
Node IP: 10.0.1.4
Pods:
  pod-A â†’ 10.244.1.10
  pod-B â†’ 10.244.1.11
```

ðŸ”‘ **Important**

- Pod IPs are **NOT routable in Azure VNet**
- Azure does **NAT** automatically

---

## 5ï¸âƒ£ Now the key part: How pods access the outside world ðŸŒ

Letâ€™s walk through **pod â†’ internet** traffic step by step.

---

## 6ï¸âƒ£ Pod â†’ Internet (Outbound traffic flow)

### Step-by-step flow

```mermaid
sequenceDiagram
    participant Pod
    participant Node
    participant AzureSNAT
    participant Internet

    Pod->>Node: Send packet (src=10.244.1.10)
    Node->>AzureSNAT: Forward traffic
    AzureSNAT->>AzureSNAT: SNAT to Node IP (10.0.1.4)
    AzureSNAT->>Internet: Send traffic
    Internet-->>AzureSNAT: Response
    AzureSNAT-->>Node: De-SNAT
    Node-->>Pod: Deliver response
```

### What actually happens

1. Pod sends traffic using **overlay IP**
2. Node forwards packet
3. Azure performs **SNAT**

   - Source IP becomes **Node IP**

4. Internet sees traffic coming from **node**
5. Return traffic is mapped back to the pod

âœ… **Pods can access the internet normally**

---

## 7ï¸âƒ£ Where does SNAT happen?

Depends on your setup:

| Scenario            | SNAT Location      |
| ------------------- | ------------------ |
| Default AKS         | Azure-managed SNAT |
| With NAT Gateway    | NAT Gateway        |
| With Azure Firewall | Firewall           |
| With Load Balancer  | Azure LB           |

ðŸ”‘ **Pod IP is never exposed externally**

---

## 8ï¸âƒ£ Pod â†’ Azure services (Storage, SQL, etc.)

### What Azure sees

- **Source IP = Node IP**
- Not the pod IP

### Implications

- Network rules must allow **node subnet**
- Service Endpoints & Private Endpoints work fine
- Identity should be done via:

  - Managed Identity
  - Workload Identity

---

## 9ï¸âƒ£ Pod-to-Pod communication (overlay internal)

### Same node

- Direct overlay networking
- No NAT

### Different nodes

- Encapsulated traffic
- Azure CNI manages routing
- Still **overlay â†’ overlay**

âœ… Fully transparent to Kubernetes

---

## ðŸ”Ÿ Incoming traffic (brief note)

Overlay affects **outbound**, not ingress much:

| Traffic Type         | How it works      |
| -------------------- | ----------------- |
| Ingress Controller   | Uses Node IP      |
| LoadBalancer Service | Uses Azure LB     |
| External client      | Never sees pod IP |

---

## 1ï¸âƒ£1ï¸âƒ£ Key advantages of Azure CNI Overlay

âœ… Massive IP savings
âœ… Native Azure integration
âœ… Supports Network Policies
âœ… Scales well for large clusters

---

## 1ï¸âƒ£2ï¸âƒ£ Limitations (important!)

âš  Pod IPs:

- Are **not visible in VNet**
- Cannot be used in Azure NSGs
- Cannot be directly routed

âš  Troubleshooting:

- Requires understanding SNAT behavior

---

## 1ï¸âƒ£3ï¸âƒ£ When should YOU use Overlay mode?

### Use Azure CNI Overlay when:

âœ” Large AKS clusters
âœ” Limited VNet IP space
âœ” Mostly outbound workloads
âœ” Microservices + autoscaling

### Avoid when:

âŒ You need pod IPs visible in VNet
âŒ Heavy pod-to-onprem routing requirements

---

## ðŸ§  Final one-line summary (memorize this)

> **In Azure CNI Overlay, pods use an internal overlay IP range, and all outbound traffic is SNATed to the nodeâ€™s VNet IP before leaving the cluster.**

If you want next, I can:

- Compare **Overlay vs Kubenet vs Azure CNI**
- Explain **NAT Gateway sizing & SNAT port exhaustion**
- Draw a **real production AKS networking design**

Just tell me ðŸ‘Œ
