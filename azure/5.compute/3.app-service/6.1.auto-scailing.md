# ‚ö° Azure App Service ‚Äì Autoscaling Deep Dive

## üõë **The Problem Without Autoscale**

Imagine you host an **e-commerce app** on Azure App Service with:

- 2 instances
- Fixed size (Standard S2 Plan)

On **Black Friday**, your users spike from 1,000 to 50,000 concurrent requests.

- Fixed size means **same number of instances** even under pressure.
- Result ‚Üí **High CPU**, slow responses, potential 502/503 errors.

---

## ‚úÖ **The Solution ‚Äì Autoscale**

**Azure Autoscale** dynamically adjusts the **number of instances** in your **App Service Plan** based on **real-time metrics** or a **predefined schedule**.

- **Scale Out** ‚Üí Add instances when demand increases.
- **Scale In** ‚Üí Remove instances when demand drops.

---

<div align="center">
  <img src="images/app-service-autoscalling-1.png" alt="App Service Autoscaling 1" style="width: 100%; border-radius: 10px; border: 2px solid white;">
</div>

---

## üß† **How It Works**

1. **Scope**
   Autoscale applies at the **App Service Plan** level, not individual apps.
   ‚Üí If multiple apps share the same plan, **they share the same scaling decision**.

2. **Trigger Types**

   - **Metric-based**: CPU, Memory, HTTP Queue Length, Custom Metrics from Application Insights.
   - **Time-based (Scheduled)**: Scale up at 9 AM, scale down at 8 PM.
   - **Predictive Scaling** (Premium v3 only): Uses **machine learning** to forecast load before it happens.

3. **Scaling Actions**

   - Changes the **instance count** (vertical scale = different feature, that‚Äôs scaling up).
   - Instances are distributed **across fault domains** for high availability.

4. **Cool-down Period**

   - After scaling, Azure waits a configurable **cool-down** period (default 5 min) before re-evaluating.
   - Prevents ‚Äúflapping‚Äù (scale in/out every minute).

---

## ‚öô **Configuration Options**

<div align="center">
  <img src="images/app-service-autoscalling-2.png" alt="App Service Autoscaling 2" style="width: 100%; border-radius: 10px; border: 2px solid white;">
</div>

---

### 1. **Metric-based Autoscale**

![1758267785338](image/6.1.auto-scailing/1758267785338.png)

Example:

- Rule: If **CPU > 70% for 5 minutes**, add 1 instance.
- Rule: If **CPU < 30% for 10 minutes**, remove 1 instance.
- Instance Range: **Min 2, Max 10**.

**Example Portal Setup:**

```ini
Metric: CPU Percentage
Operator: Greater than
Threshold: 70
Duration: 5 minutes
Action: Increase count by 1
```

---

### 2. **Scheduled Autoscale**

![1758267791954](image/6.1.auto-scailing/1758267791954.png)

Example:

- **Weekdays**: Min 5, Max 15 (office hours load)
- **Weekends**: Min 2, Max 5 (lower traffic)

---

### 3. **Predictive Autoscale** _(Premium v3 / Elastic Premium)_

- Uses historical traffic to **forecast demand**.
- Starts scaling **before** the spike.
- Example: If data shows a spike every day at 8:55 AM, Azure starts adding instances at 8:50 AM.

---

## üìà **Auto-Scaling Metrics**

Azure App Service provides an extensive range of metrics that support effective auto-scaling across all application instances. Key metrics include:

| Metric Type       | Description                          |
| ----------------- | ------------------------------------ |
| CPU Percentage    | Monitors processor utilization       |
| MemoryPercentage  | Tracks memory consumption            |
| Disk Queue Length | Measures disk I/O performance        |
| HTTP Queue Length | Evaluates the HTTP request queue     |
| Data In/Out       | Monitors the volume of data transfer |

These metrics enable you to fine-tune your auto-scaling configuration, ensuring that your service adjusts dynamically to real-world usage patterns.

![1758267924098](image/6.1.auto-scailing/1758267924098.png)

---

## üîç **Under the Hood ‚Äì Scaling Logic**

1. Azure Monitor collects metrics every **minute**.
2. Metrics are compared against autoscale rules.
3. If a threshold is breached ‚Üí Scale Action Triggered.
4. App Service adds/removes instances within **your min/max limits**.
5. Instance warm-up time usually \~1-2 min for App Service.

---

## üí° **Real Example**

You have:

- Plan: Premium v3
- Rules:

  - CPU > 80% for 5 min ‚Üí Add 2 instances.
  - HTTP Queue Length > 100 ‚Üí Add 1 instance.
  - CPU < 30% for 10 min ‚Üí Remove 1 instance.

- Min: 2 instances
- Max: 8 instances

**Scenario:**

- Traffic spike ‚Üí CPU hits 85% ‚Üí App Service adds 2 instances ‚Üí now 4 total.
- Traffic keeps increasing ‚Üí HTTP Queue hits 150 ‚Üí adds 1 more instance ‚Üí now 5.
- At night ‚Üí CPU drops to 20% ‚Üí scales in gradually to min 2.

---

## üìå **Key Considerations**

- Scaling is **per region** ‚Äî if your app is deployed in multiple regions, autoscale rules apply to each separately.
- Warm-up time matters ‚Äî for bursty traffic, **Predictive Scaling** is more effective.
- Scaling out ‚â† Scaling up:

  - **Scale Out** = more instances.
  - **Scale Up** = bigger instance SKU (vCPU/RAM).

---

## üéØ **Pro Tip**

For **mission-critical apps**, combine:

- **Predictive Autoscale** (to handle known spikes)
- **Metric-based Autoscale** (to handle unexpected load)
- **Minimum instance buffer** (so you don‚Äôt start from zero during spikes)
