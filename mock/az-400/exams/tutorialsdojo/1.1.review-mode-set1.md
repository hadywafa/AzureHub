# üìã Review Mode Set 1

## ‚ÅâÔ∏è Q7

<div align="left">
  <img src="image/1.1.review-mode-set1/1757421989331.png" alt="1757421989331" style="width: 80%; border-radius: 10px; border: 2px solid white;">
</div>

---

> üëâüèª **Explanation**  
> To monitor the performance of the Azure Kubernetes Service (AKS) cluster, it is crucial to set up alerts in Azure Monitor. For this specific requirement, configuring the alert rule with an aggregation granularity of 1 minute ensures frequent evaluation of CPU usage, providing timely and accurate monitoring. This high frequency of data collection is essential for detecting short-term spikes in CPU usage that might be missed with longer aggregation periods.
>
> Using a static threshold type is appropriate in this context because the requirement specifies monitoring a fixed threshold of 80%. Static thresholds are straightforward and effective when you need to monitor specific values. The operator should be set to ‚Äúgreater than‚Äù to ensure the alert activates only when the CPU usage surpasses the defined threshold of 80%, providing a clear and unambiguous trigger point for the alert. This configuration ensures that any excessive CPU usage is promptly flagged, allowing for quick action to maintain the performance and reliability of the AKS cluster.
>
> This configuration ensures effective monitoring of the AKS cluster‚Äôs performance, allowing you to take necessary actions when the CPU usage exceeds acceptable limits, thereby maintaining the application‚Äôs efficiency and reliability.
>
> Hence, the correct answers are:
>
> - Period: 1 minute.
>
> - Threshold Type: Static.
>
> - Operator: Greater than.
>
> The option that says: 5 minutes is incorrect. Setting the aggregation granularity to 5 minutes would mean that the CPU usage is evaluated less frequently. This could delay the detection of high CPU usage, making the alert less responsive and potentially missing short spikes in CPU usage that last less than 5 minutes.
>
> The option that says: Dynamic is incorrect because a dynamic threshold adjusts based on historical data and trends, which might be useful for identifying unusual patterns. However, it does not suit scenarios where a specific threshold value (like 80 percent CPU usage) needs to be monitored consistently.

---

## ‚ÅâÔ∏è Q8

<div align="left">
  <img src="image/1.1.review-mode-set1/1757422532728.png" alt="1757422532728" style="width: 80%; border-radius: 10px; border: 2px solid white;">
</div>

---

> üëâüèª **Explanation**
>
> <div align="left">
>   <img src="image/1.1.review-mode-set1/1757422563831.png" alt="1757422563831" style="width: 80%; border-radius: 10px; border: 2px solid white;">
> </div>
> Dependency Tracker extension in Azure DevOps is a powerful tool designed to visualize and manage project dependencies. This extension allows project managers to see a comprehensive overview of all interdependencies between various projects, highlighting the connections between consumers and producers. A visual representation of these dependencies helps identify potential bottlenecks, ensuring that any issues can be addressed promptly to maintain smooth integration and timely delivery. The tool seamlessly integrates with Azure DevOps, allowing easy incorporation into existing workflows without requiring significant changes or additional development effort.
>
> With the Dependency Tracker extension, project managers can effectively plan and manage project timelines. This helps ensure that all teams are aligned and dependencies are well-coordinated, reducing the risk of delays caused by overlooked dependencies or team miscommunications. The extension provides real-time updates and detailed insights into the status of dependencies, making it an invaluable asset for large software development companies with multiple teams and projects. This ensures that projects are delivered on time and integration issues are minimized, leading to more efficient and successful project outcomes.

---

## ‚ÅâÔ∏è Q9

<div align="left">
  <img src="image/1.1.review-mode-set1/1757424441572.png" alt="1757424441572" style="width: 80%; border-radius: 10px; border: 2px solid white;">
</div>

---

> üëâüèª **Explanation**
> Azure DevOps pipelines are essential for automating the build and deployment processes of applications. However, when issues arise, especially intermittent ones, diagnosing the root cause can be challenging with default logging levels. Enabling detailed logging in Azure DevOps can significantly improve the visibility into the pipeline‚Äôs execution, capturing comprehensive information that is crucial for troubleshooting.
>
> To enable detailed logging, the predefined variable `System.Debug` must be set to `true`. This variable controls the verbosity of the logs generated during the pipeline runs. When System.Debug is set to true, Azure DevOps produces more granular logs, including detailed information about each task, command outputs, and potential error messages. This enhanced level of detail is invaluable when diagnosing complex issues that are not apparent with standard logging levels.
>
> <div align="left">
>   <img src="image/1.1.review-mode-set1/1757424518580.png" alt="1757424518580" style="width: 80%; border-radius: 10px; border: 2px solid white;">
> </div>
>
> In practice, you can enable detailed logging by setting the System.Debug variable in your pipeline definition. For YAML pipelines, this involves adding System.Debug: true under the variables section. For pipelines configured through the Classic UI, you can add the variable in the pipeline settings under the variables section with Name: System.Debug and Value: true. Once this configuration is applied and the pipeline is run, the logs will include detailed information, providing greater insights into the execution flow and helping to identify and resolve issues more effectively.

---

## ‚ÅâÔ∏è Q11

<div align="left">
  <img src="image/1.1.review-mode-set1/1757426293406.png" alt="1757426293406" style="width: 80%; border-radius: 10px; border: 2px solid white;">
</div>

---

> üëâüèª **Explanation**  
> Microsoft-hosted Agents: Microsoft-hosted agents are virtual machines managed by Microsoft and used to run your build and release jobs in Azure Pipelines. These agents are shared resources, meaning multiple users and projects can utilize them simultaneously. Microsoft-hosted agents come with pre-installed software and tools, making them convenient for quick setup and use.
>
> They have time limits (timeouts) for job execution to ensure fair usage of shared resources.
>
> Public project: 10 free Microsoft-hosted parallel jobs that can run for up to 360 minutes (6 hours) each time, with no overall time limit per month.
>
> Private project: One free parallel job that can run for up to 60 minutes each time, until you‚Äôve used 1,800 minutes (30 hours) per month. You can pay for additional capacity per parallel job. Paid parallel jobs remove the monthly time limit and allow you to run each job for up to 360 minutes (6 hours).
>
> If your build job exceeds the timeout threshold, it will be canceled, leading to failures.
>
> Self-hosted Agents: Self-hosted agents are virtual machines or physical machines that you provision and maintain yourself. These agents are dedicated to your organization or project and are not shared with other users. Self-hosted agents give you more control over the environment, allowing you to install specific software, tools, and dependencies required for your build and release processes.
>
> These agents can be physical or virtual machines, either on-premises or in the cloud (e.g., Azure Virtual Machines).
>
> Self-hosted agents do not have the same timeout restrictions as Microsoft-hosted agents, allowing your build job to run for as long as necessary.
>
> You have full control over the machine‚Äôs resources and can customize the environment to meet your specific build requirements.
>
> By using a self-hosted agent, you can customize the build environment, allocate sufficient resources, and eliminate the timeout restrictions imposed by Microsoft-hosted agents. This approach provides more control and flexibility over the build process, increasing the likelihood of successful builds for the TutorialsWebApp application.

---

## ‚ÅâÔ∏è Q14

<div align="left">
  <img src="image/1.1.review-mode-set1/1757426648772.png" alt="1757426648772" style="width: 80%; border-radius: 10px; border: 2px solid white;">
</div>

---

> üëâüèª **Explanation**  
> Yeoman is a robust scaffolding tool that simplifies the creation of Terraform modules. It helps by generating standardized templates, which reduces manual effort and ensures consistency across your infrastructure code. Using Yeoman, you can quickly set up Terraform modules with the necessary structure and files, making it easier to manage and deploy infrastructure on Azure.
>
> Terratest provides a robust framework for testing infrastructure. It includes helper functions for common tasks like making HTTP requests and using SSH, which help verify the real infrastructure in its environment. Key advantages include:
>
> - Convenient Helpers: This function is useful for verifying your actual infrastructure in a real-world scenario.
>
> - Organized Folder Structure: Ensures clarity and follows standard Terraform module structure.
>
> - Written in Go: Many Terraform users are Go developers, allowing seamless integration without needing another language.
>
> - Extensible: Allows adding functions, including Azure-specific features.

---

## ‚ÅâÔ∏è Q17

<div align="left">
  <img src="image/1.1.review-mode-set1/1757431342039.png" alt="1757431342039" style="width: 80%; border-radius: 10px; border: 2px solid white;">
</div>

---

> üëâüèª **Explanation**  
> **Test Impact Analysis (TIA)** in Azure Pipelines reduces test execution time by selectively running only the tests affected by recent code changes. This targeted approach is particularly beneficial in continuous integration (CI) environments, where minimizing testing duration is essential. TIA ensures that only the necessary tests are run, allowing for quicker feedback loops while still maintaining code coverage.
> References:
>
> <https://learn.microsoft.com/en-us/azure/devops/pipelines/test/test-impact-analysis?view=azure-devops>
>
> <https://learn.microsoft.com/en-us/azure/devops/pipelines/test/parallel-testing-vstest?view=azure-devops>
>
> Check out these Microsoft Azure Cheat Sheets:
>
> <https://tutorialsdojo.com/microsoft-azure-cheat-sheets/>

---

## ‚ÅâÔ∏è Q21

<div align="left">
  <img src="image/1.1.review-mode-set1/1757432560713.png" alt="1757432560713" style="width: 80%; border-radius: 10px; border: 2px solid white;">
</div>

---

> üëâüèª **Explanation**  
> The `.artifactignore` file in Azure DevOps is used to specify which files should be included or excluded when publishing build artifacts. This is particularly useful in scenarios where you want to optimize the build process by only including necessary files and excluding others that are not needed for deployment.
>
> <div align="left">
>   <img src="image/1.1.review-mode-set1/1757432607343.png" alt="1757432607343" style="width: 20%; border-radius: 10px; border: 2px solid white;">
> </div>

---

## ‚ÅâÔ∏è Q26

<div align="left">
  <img src="image/1.1.review-mode-set1/1757433217387.png" alt="1757433217387" style="width: 80%; border-radius: 10px; border: 2px solid white;">
</div>

---

> üëâüèª **Explanation**
>
> üìå **Why this is correct**
>
> 1. **Deployment gates** in Azure DevOps are designed for **quality checks before promotion** (pre-deployment approvals, compliance checks, policy validation, etc.).
> 2. Azure DevOps provides a built-in **Security & Compliance Assessment extension/task** that integrates with **Azure Policy**, ensuring the resources about to be deployed are compliant.
> 3. If non-compliant, the gate **blocks promotion** to the next stage ‚Üí exactly what the requirement asked.
>
> So this solution is **native, automated, and policy-driven**.
>
> ---
>
> ‚ùå **Why the other options are wrong**
>
> 1. **Azure Logic App** ‚Üí
>
>    - Logic Apps can monitor resources, but this is an **external workflow**.
>    - Exam wants you to use **built-in DevOps gates** rather than bolting on extra services.
>
> 2. **Custom script** ‚Üí
>
>    - Possible, but not recommended because it‚Äôs **manual & error-prone**.
>    - Azure DevOps already provides a first-class task for policy compliance.
>
> 3. **Azure Automation with What-If deployment** ‚Üí
>
>    - The What-If operation validates **template changes** (what resources will be created/modified), but it does **not enforce Azure Policy compliance**.
>    - So, it solves drift detection, not compliance enforcement.

---

## ‚ÅâÔ∏è Q28

<div align="left">
  <img src="image/1.1.review-mode-set1/1757435213246.png" alt="1757435213246" style="width: 80%; border-radius: 10px; border: 2px solid white;">
</div>

---

> üëâüèª **Explanation**  
> Microsoft Playwright Testing Preview is a fully managed end-to-end testing service built on the Playwright framework. It allows you to automate tests to ensure your web applications perform as expected across various web browsers and operating systems. The service simplifies the complexity of running Playwright tests and handling results and artifacts. With high parallelization, it runs tests efficiently and stores results and artifacts, enabling faster feature delivery and easier troubleshooting.
>
> By using Microsoft Playwright Testing Preview, you can continuously validate your web app‚Äôs performance across different browsers and operating systems with each code commit, and troubleshoot tests with ease using the service dashboard. Additionally, you can integrate your Playwright tests into a continuous integration (CI) workflow, such as GitHub Actions, Azure Pipelines, or other CI platforms.

---

## ‚ÅâÔ∏è Q30

<div align="left">
  <img src="image/1.1.review-mode-set1/1757436454919.png" alt="1757436454919" style="width: 80%; border-radius: 10px; border: 2px solid white;">
</div>

---

> üëâüèª **Explanation**  
> Azure PowerShell refers to the collection of official Microsoft PowerShell modules for managing Azure resources. It leverages PowerShell, which is both a command-line shell and a scripting language. You can use Azure PowerShell interactively by running individual commands in the PowerShell environment or by creating and executing scripts composed of multiple commands.

---

## ‚ÅâÔ∏è Q31

<div align="left">
  <img src="image/1.1.review-mode-set1/1757436747499.png" alt="1757436747499" style="width: 80%; border-radius: 10px; border: 2px solid white;">
</div>

---

> üëâüèª **Explanation**
>
> üìù **Scenario**
>
> - Pipeline has tests.
> - Some tests depend on 3rd party services (can be <ins title="ÿ®ÿ¥ŸÉŸÑ ŸÖÿ™ŸÇÿ∑ÿπ" style="cursor:help">**intermittently</ins> down**) ‚Üí false negatives.
> - Requirement ‚Üí Pipeline should **still succeed** even if these flaky tests fail.
>
> ---
>
> ‚úÖ **Correct Exam Answer**
>
> üëâ **Set up flaky tests.**
>
> Why?
>
> - Azure Pipelines has **built-in flaky test management**.
> - A flaky test = a test that fails intermittently but passes on retry.
> - Azure DevOps can **auto-detect flaky tests** and mark them as such, so they **don‚Äôt fail the pipeline**.
> - This is the **official feature** designed for this scenario.
>
> ---
>
> ü§î **Why not `always()` condition?**
>
> You‚Äôre right ‚Äî you **could** wrap test steps like this:
>
> ```yaml
> - task: VSTest@2
>   condition: always()
> ```
>
> But here‚Äôs the subtle difference:
>
> - `always()` just means ‚Üí this step will **run regardless of previous failures**.
> - If the tests fail, the **job/pipeline can still fail** unless you also suppress errors (`continueOnError: true`).
>
> Example:
>
> ```yaml
> - task: VSTest@2
>   inputs:
>     testSelector: "testAssemblies"
>   continueOnError: true
> ```
>
> This would indeed allow the pipeline to pass despite test failures.
>
> ‚ö†Ô∏è Problem: That means **all test failures are ignored**, not just flaky ones.
>
> - You lose visibility into **real bugs** vs. **flaky issues**.
> - Dangerous in practice ‚Üí may ship broken code.
>
> ---
>
> üîÑ **Difference Between Approaches**
>
> | Approach                           | Behavior                                                                                  | Best For                                                                |
> | ---------------------------------- | ----------------------------------------------------------------------------------------- | ----------------------------------------------------------------------- |
> | **Flaky test setup**               | Auto-detects intermittent failures, retries test, marks it as flaky if it passes on retry | Handling unreliable external dependencies without masking real failures |
> | **`always()` + `continueOnError`** | Ignores failures entirely (or still reports but doesn‚Äôt break build)                      | Non-critical steps (e.g., publishing test coverage, uploading logs)     |
> | **Lowering pass threshold**        | Accepts failures if % is ‚Äúgood enough‚Äù                                                    | Rarely used, risky in enterprise                                        |
> | **Concurrent jobs**                | Runs tests in parallel                                                                    | Performance optimization, not reliability                               |

---

## ‚ÅâÔ∏è Q33

<div align="left">
  <img src="image/1.1.review-mode-set1/1757437863637.png" alt="1757437863637" style="width: 80%; border-radius: 10px; border: 2px solid white;">
</div>

---

> üëâüèª **Explanation**
>
> ‚ùì The Question
>
> You need to:
>
> - Take commits from a **feature branch**
> - Update the **main branch**
> - Keep commit history **clean and organized** (no messy merge commits)
>
> ---
>
> ‚úÖ Correct Answer: **`git rebase`**
>
> üëâ `git rebase` takes the commits from your feature branch and **re-applies them** on top of the target branch (main).
>
> - This makes it look like your work was done **after the latest main branch commit**, even if main moved forward.
> - Result: a **linear history** ‚Üí no unnecessary merge bubbles.
>
> Example:
>
> ```bash
> # Switch to your feature branch
> git checkout feature
>
> # Rebase onto main
> git rebase main
> ```
>
> This rewrites history ‚Üí feature commits now look like they came **after main‚Äôs latest commit**.
>
> ---
>
> ‚ùå Why Not the Others?
>
> 1. **Cherry-pick**
>
>    - Applies a **single commit** from one branch to another.
>    - Good for hotfixes or one-off commits.
>    - ‚ùå Not for updating whole feature branch history ‚Üí would be painful to cherry-pick many commits.
>
> 2. **Fetch**
>
>    - Just downloads objects/refs from a remote.
>    - ‚ùå Doesn‚Äôt update history or apply commits ‚Üí only syncs metadata.
>
> ---
>
> üéØ Exam Keyword Trick
>
> When you see:
>
> - "Override history"
> - "Keep commit log clean and organized"
> - "Linear history"
>
> üëâ Always think **`git rebase`**.
>
> ---
>
> ‚ö° So:
>
> - Cherry-pick = one commit
> - Rebase = clean, linear branch history
> - Merge = keeps both histories (can be messy)
> - Fetch = update refs only

---
