# ğŸ“‹ Review Mode Set 1

## â‰ï¸ Q2

<div align="left">
  <img src="image/1.review-mode-set1/1759422076434.png" alt="1759422076434" style="width: 80%; border-radius: 10px; border: 2px solid white;">
</div>

---

> ğŸ‘‰ğŸ» **Explanation**
>
> **âœ… The Answer:**
>
> - **List â†’ Maintain a queue of tasks to process user-generated requests in the order they are received.**
> - **Channel â†’ Implement a publish/subscribe mechanism for real-time notifications.**
> - **Set â†’ Store unique user roles efficiently to prevent duplication.**
>
> ---
>
> **ğŸ¤” Why This Is the Best Answer:**
>
> Redis Provide a lot of data structure types each one for its specific purpose
>
> - **List** works like a queue (FIFO or LIFO), making it ideal for handling tasks sequentially in the order they were generated.
> - **Channel** enables a **pub/sub** model, perfect for broadcasting real-time notifications between distributed application components.
> - **Set** guarantees uniqueness, which is crucial for storing roles, tags, or IDs without duplicates.
>
> These match exactly with the questionâ€™s requirements for **queuing**, **real-time messaging**, and **role management**.
>
> ---
>
> **âŒ Why Other Options Are Wrong:**
>
> - **Sorted Set:** While it supports ordered elements with scores (useful for leaderboards or priority queues), the scenario does not require scoring or rankingâ€”only a simple task queue, which **List** handles better.
> - **Hash:** Useful for structured objects (e.g., user profiles with multiple fields), but it does not enforce uniqueness (like **Set**) or ordered task handling (like **List**), nor does it support messaging.
>
> ğŸ‘‰ Correct matches are **List, Channel, and Set**, not **Sorted Set** or **Hash**.
>
> References:
>
> - <https://learn.microsoft.com/en-us/azure/architecture/best-practices/caching>
> - <https://learn.microsoft.com/en-us/azure/azure-cache-for-redis/cache-overview>

---

## â‰ï¸ Q3

<div align="left">
  <img src="image/1.review-mode-set1/1759422562123.png" alt="1759422562123" style="width: 80%; border-radius: 10px; border: 2px solid white;">
</div>

---

> ğŸ‘‰ğŸ» **Explanation**
>
> **âœ… The Answer:**
>
> - Active Directory Integrated authentication mode
>
> **ğŸ“– Explanation:**
>
> - Microsoft Entra ID provides centralized management for the identities of both individuals and services within your data estate. By integrating it with Azure SQL for authentication, you can streamline identity and access management while gaining enhanced conditional access controls and governance over all data connections.
> - To enable the Active Directory Integrated authentication mode, an on-premises Active Directory instance linked to Microsoft Entra ID in the cloud is required. Federation can be achieved using tools such as Active Directory Federation Services (AD FS).
> - With this mode, users signed in to a domain-joined machine can access Azure SQL data sources seamlessly without credential prompts. However, you cannot include a username and password in the connection string for .NET Framework applications. For .NET Core and .NET Standard applications, including a username in the connection string is optional. Additionally, the Credential property of the SqlConnection cannot be configured when using this mode.
>
> <div align="left">
>   <img src="image/1.review-mode-set1/1759422719850.png" alt="1759422719850" style="width: 80%; border-radius: 10px; border: 2px solid white;margin: 0 30px">
> </div>
>
> ---
>
> **âŒ Why Other Options Are Wrong:**
>
> - **Active Directory Interactive authentication** is incorrect because it requires user interaction and prompts for authentication each time. This contradicts the requirement to minimize authentication prompts. It is typically used when Multi-Factor Authentication (MFA) is required.
>
> - **Microsoft Entra ID tokens** is incorrect because token-based authentication is primarily used for applications and services, not for direct user authentication through SSMS. It does not allow seamless authentication for users without manual intervention.
>
> - **SQL Server Authentication** is incorrect because it requires a username and password to be entered manually for every connection. It does not support integration with Microsoft Entra ID or on-premises Active Directory, making it unsuitable for the given requirements.
>
> ---
>
> ğŸ“š **References:**
>
> - <https://learn.microsoft.com/en-us/azure/azure-sql/database/authentication-aad-overview?view=azuresql>
> - <https://learn.microsoft.com/en-us/sql/connect/ado-net/sql/azure-active-directory-authentication?view=sql-server-ver16#using-integrated-authentication>
> - <https://learn.microsoft.com/en-us/entra/identity/hybrid/connect/whatis-fed>

---

## â‰ï¸ Q4

<div align="left">
  <img src="image/1.review-mode-set1/1759423565265.png" alt="1759423565265" style="width: 80%; border-radius: 10px; border: 2px solid white;">
</div>

---

> ğŸ‘‰ğŸ» **Explanation**
>
> **âœ… The Answer:**
>
> - `Telemetry.id`.
> - `Telemetry.Context.Operation.Id`.
>
> **ğŸ“– Explanation:**
>
> - When monitoring complex applications, especially those that interact with external services like payment gateways, **Telemetry.id** and **Telemetry.Context.Operation.Id** are crucial for ensuring comprehensive traceability and understanding the flow of requests.  
>   **Telemetry.id** uniquely identifies each telemetry item, providing a distinct reference for every event or dependency tracked within Application Insights. This allows you to pinpoint and analyze specific interactions with external services, such as the payment gateway. By associating each interaction with a unique ID, you can follow the lifecycle of a request through its various stages, helping you identify issues or delays in specific transactions. This granularity is significant in troubleshooting and debugging scenarios, as it allows you to track the exact flow of a transaction from start to finish.
> - **Telemetry.Context.Operation.Id** is equally important as it ties together multiple telemetry events under a single operation. In a distributed system, a single user request might involve multiple services. By using the Operation.Id, you can link these various components and track them as a unified operation. This property enables end-to-end tracing, allowing you to correlate telemetry across different services and gain insights into the overall performance of a user transaction. With this context, you can identify bottlenecks, measure service performance, and ensure that all system parts work harmoniously. In the case of a payment gateway interaction, Operation.Id allows you to tie the payment process back to the original user request, ensuring that you have a complete view of how the payment gateway fits into the broader application flow.
> - By combining **Telemetry.id** unique event tracking and **Telemetry.Context.Operation.Id**. For distributed tracing, Azure Application Insights offers a powerful mechanism to monitor, diagnose, and optimize applications that depend on external services. These properties provide the necessary context to understand the full scope of user interactions with external dependencies and help ensure that performance issues or failures are swiftly identified and addressed. This approach leads to better reliability, faster troubleshooting, and improved overall application health, particularly in systems where multiple services interact in complex workflows.
>
> ---
>
> **ğŸ§  What Is Telemetry?**
>
> **Telemetry** just means: _â€œdata your app sends about itself.â€_
>
> Think of it like your app whispering:
>
> > â€œHey, I just got a request.â€  
> > â€œI called the payment gateway.â€  
> > â€œOops, something crashed.â€  
> > â€œHereâ€™s how long that SQL query took.â€
>
> Application Insights collects these whispers and turns them into charts, logs, and maps.
>
> ---
>
> **ğŸ” Key Concepts in App Insights:**
>
> | Concept                  | What It Means                                                                |
> | ------------------------ | ---------------------------------------------------------------------------- |
> | **Request Telemetry**    | Tracks incoming HTTP requests to your app                                    |
> | **Dependency Telemetry** | Tracks outbound calls (SQL, HTTP, Service Bus, etc.)                         |
> | **Exception Telemetry**  | Captures errors and stack traces                                             |
> | **Trace Telemetry**      | Custom logs you write (e.g., `logger.LogInformation(...)`)                   |
> | **Operation.Id**         | Unique ID for a full transaction (e.g., placing an order)                    |
> | **ParentId**             | ID of the parent request (e.g., API call that triggered a SQL query)         |
> | **Telemetry.Id**         | ID of the individual telemetry item (e.g., one SQL call or one HTTP request) |
> | **Session.Id**           | Tracks user session across multiple requests (less useful for correlation)   |
>
> ---
>
> **ğŸ§­ Why This Matters for Distributed Systems:**
>
> In cloud-native apps, you often have:
>
> - Frontend â†’ API â†’ SQL + Payment Gateway + Service Bus â†’ Azure Function
>
> You want to **correlate all those pieces** into one trace. Thatâ€™s where:
>
> - `Operation.Id` = ties everything together
> - `ParentId` = shows who triggered what
> - `Telemetry.Id` = identifies each piece
> - `Session.Id` = tracks user behavior (not technical correlation)
>
> ---
>
> **ğŸ§  In Your Quiz Scenario:**
>
> Youâ€™re integrating with a **third-party payment gateway**. To track that interaction and link it to the full order transaction, you need:
>
> âœ… `Telemetry.Context.Operation.Id` â†’ links the payment call to the overall order  
> âœ… `Telemetry.Context.Operation.ParentId` â†’ shows the API call that triggered the payment
>
> The selected answers (`Session.Id` and `Telemetry.Id`) arenâ€™t wrong, but theyâ€™re **not ideal for correlation**:
>
> - `Session.Id` is more about user tracking
> - `Telemetry.Id` is just the ID of one telemetry itemâ€”not enough to link things together
>
> ---
>
> **ğŸ§  Analogy:**
>
> Imagine you're tracking a pizza order:
>
> - `Operation.Id` = the whole order
> - `ParentId` = the call to the delivery service
> - `Telemetry.Id` = the delivery confirmation
> - `Session.Id` = the customer browsing history
>
> ---
>
> ğŸ“š **References:**
>
> - <https://learn.microsoft.com/en-us/azure/azure-monitor/app/data-model-complete>
> - <https://learn.microsoft.com/en-us/azure/azure-monitor/app/transaction-search-and-diagnostics?tabs=transaction-search>

---

## â‰ï¸ Q5

<div align="left">
  <img src="image/1.review-mode-set1/1759427542045.png" alt="1759427542045" style="width: 80%; border-radius: 10px; border: 2px solid white;">
</div>

---

> ğŸ‘‰ğŸ» **Explanation**
>
> **âœ… The Answer:**
>
> - **AppServiceEnvironmentPlatformLogs**
>
> **ğŸ“– Explanation:**
>
> - App Service Environments (ASE) host web applications in an isolated and highly scalable hosting environment. To track **configuration changes** at the ASE level, Azure Monitor provides **AppServiceEnvironmentPlatformLogs**, which record platform-level events such as configuration modifications, scaling operations, and infrastructure-related issues. These logs are essential for auditing and troubleshooting unexpected changes that affect compliance or stability.
>
> <div align="left">
>   <img src="image/1.review-mode-set1/1759427853653.png" alt="1759427853653" style="width: 80%; border-radius: 10px; border: 2px solid white;">
> </div>
>
> **ğŸ¤” Why This Is the Best Answer:**
>
> - The question specifically mentions unexpected **configuration modifications applied in the App Service Environment (ASE)**.
> - **AppServiceEnvironmentPlatformLogs** are designed to capture **platform-level events**, making them the correct source for identifying such changes.
> - This directly aligns with the requirement of monitoring **configuration changes for ASE** to ensure compliance and resolve issues.
>
> **âŒ Why Other Options Are Wrong:**
>
> - **AppServiceAppLogs:** Captures application-level diagnostics such as errors, traces, and custom logs generated by the app itself. It does not track configuration changes to the ASE platform.
> - **AzureResourceChangesLogs:** Refers to Azure Resource Graph/Activity Logs that record create, update, and delete operations on Azure resources at the subscription level. While useful for auditing, it does not provide ASE-specific configuration change tracking.
> - **AzureDiagnosticsLogs:** These logs capture diagnostic data from different Azure resources, such as performance metrics or telemetry, but are not specialized for ASE platform configuration changes.
>
> **ğŸ“š References:**
>
> - [https://learn.microsoft.com/en-us/azure/azure-monitor/app/app-service-environment](https://learn.microsoft.com/en-us/azure/azure-monitor/app/app-service-environment)
> - [https://learn.microsoft.com/en-us/azure/azure-monitor/essentials/platform-logs-overview](https://learn.microsoft.com/en-us/azure/azure-monitor/essentials/platform-logs-overview)
> - <https://learn.microsoft.com/en-us/azure/app-service/troubleshoot-diagnostic-logs>
> - <https://learn.microsoft.com/en-us/azure/azure-monitor/reference/tables/appserviceenvironmentplatformlogs>
> - <https://learn.microsoft.com/en-us/azure/app-service/environment/using>

---

## â‰ï¸ Q8

<div align="left">
  <img src="image/1.review-mode-set1/1759435690008.png" alt="1759435690008" style="width: 80%; border-radius: 10px; border: 2px solid white;">
</div>

---

> ğŸ‘‰ğŸ» **Explanation**
>
> **âœ… The Answer:**
>
> - **Use the Logic App Code View option in the Azure portal.**
>
> **ğŸ“– Explanation:**
>
> - When building enterprise integration solutions with automated workflows in Azure Logic Apps, the workflow definitions are described and validated using simple, declarative JSON and the Workflow Definition Language (WDL) schema. These formats are designed to be easily readable and understandable, even for those with minimal coding knowledge. To automate the creation and deployment of logic app resources, you can include workflow definitions as Azure resources in Azure Resource Manager templates. Logic apps can be created, managed, and deployed using Azure PowerShell, Azure CLI, or the Azure Logic Apps REST APIs.
> - To edit workflow definitions in JSON, you can use the code view editor in the Azure portal or Visual Studio Code. Additionally, you can copy and paste the definitions into any preferred editor.
> - In the Azure portal, Azure Logic Apps allows you to edit workflows either visually or programmatically. Once you open a logic app resource, navigate to the resource menu under â€œDeveloperâ€ to choose between the Code view and the Designer view. Use the Designer view to visually create, edit, and execute your workflow. You can seamlessly switch between the Designer view and Code view whenever needed.
> - In Code view, you can directly modify the workflow definition file in JSON format. Remember to click Save to apply any changes you make in this mode.
>
> <div align="left">
>   <img src="image/1.review-mode-set1/1759435822344.png" alt="1759435822344" style="width: 80%; border-radius: 10px; border: 2px solid white;margin: 0 30px">
> </div>
>
> ---
>
> **âŒ Why Other Options Are Wrong:**
>
> - **Delete the existing Logic App and create a new one with the updated logic:** is incorrect because this approach is inefficient and unnecessary. Deleting the Logic App results in the loss of execution history, logs, and connections, requiring a complete redeployment. Azure provides built-in editing capabilities that allow updates without creating a new instance.
>
> - **Modify the Logic App in the Azure portal using the Designer view:** is incorrect because while the Designer view enables workflow modifications, it does not offer full control over the workflow definition, especially for advanced customizations. Some configurations and complex logic adjustments can only be made using Code View.
>
> - **Export the Logic App as an ARM template, modify the workflow definition, and redeploy:** is incorrect because this method is primarily used for infrastructure as code (IaC) scenarios, such as managing Logic Apps through automation or version control. While valid for deployments, it is not the most efficient way to modify an existing Logic App instance, as it requires redeployment rather than direct in-place updates.

---
